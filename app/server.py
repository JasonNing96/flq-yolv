"""
FLQ-Fed è”é‚¦å­¦ä¹ æœåŠ¡å™¨
ç®€åŒ–ç‰ˆ - é›†ä¸­æ‰€æœ‰æœåŠ¡å™¨é€»è¾‘
åŒ¹é… flq_yolov_v8.py (FreezeBN Version)
"""
import os
import torch
import gc
from pathlib import Path
from datetime import datetime
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Dict, List, Optional, Any
import uvicorn

from .config import Config
from .model_utils import (
    state_dict_to_vector, vector_to_state_dict,
    fedavg_aggregate, compute_model_size, compute_compression_ratio,
    state_dict_to_grad_vector,
    FLQCompressor # ä½¿ç”¨ç»Ÿä¸€çš„å‹ç¼©å™¨ç±»
)


# ==================== æ•°æ®æ¨¡å‹ ====================

class UpdateRequest(BaseModel):
    """å®¢æˆ·ç«¯ä¸Šä¼ æ›´æ–°çš„è¯·æ±‚"""
    client_id: int
    grad_vector: List[float]  # åºåˆ—åŒ–çš„æ¢¯åº¦å‘é‡ (æˆ–é‡åŒ–åçš„æ•´æ•°å‘é‡)
    n_samples: int
    round_id: int
    metrics: Optional[Dict[str, float]] = None
    bits_up: Optional[float] = None
    quant_params: Optional[Dict[str, Any]] = None # {scale, zero_point, bits}


class StatusResponse(BaseModel):
    """æœåŠ¡å™¨çŠ¶æ€å“åº”"""
    current_round: int
    total_rounds: int
    training_done: bool
    buffered_updates: int
    clients_per_round: int
    waiting_for: int
    aggregation_mode: str
    avg_map50: Optional[float] = None
    avg_loss: Optional[float] = None
    round_time: Optional[float] = None
    bits_down_total_round: Optional[float] = None
    bits_up_total_round: Optional[float] = None


# ==================== æœåŠ¡å™¨çŠ¶æ€ ====================

class ServerState:
    """æœåŠ¡å™¨å…¨å±€çŠ¶æ€"""
    
    def __init__(self, config: Config, initial_model):
        self.config = config
        self.model = initial_model
        # ä¿æŒ state_dict åœ¨ CPU ä»¥èŠ‚çœæ˜¾å­˜
        self.global_state = {k: v.cpu() for k, v in initial_model.model.state_dict().items()}
        self.last_global_state = {k: v.clone() for k, v in self.global_state.items()}

        # è®­ç»ƒçŠ¶æ€
        self.current_round = 0
        self.training_done = False

        # ç¼“å†²åŒº
        self.update_buffer = []
        self.sample_counts = []
        self.metrics_buffer = []
        self.bits_up_buffer = []

        # ç»Ÿè®¡ä¿¡æ¯
        self.round_start_time = None
        self.round_metrics = {}
        self.total_params, self.model_size_mb = compute_model_size(self.global_state, 32)
        self.bits_down_per_round = 0

        print(f"[{self._ts()}] ğŸ“¦ æ¨¡å‹å‚æ•°: {self.total_params:,} ({self.model_size_mb:.1f} MB)")
        print(f"[{self._ts()}] ğŸ¯ è®­ç»ƒç›®æ ‡: {config.rounds} è½® Ã— {config.clients_per_round} å®¢æˆ·ç«¯")
        print(f"[{self._ts()}] âš™ï¸  æ¨¡å¼: {config.aggregation_mode} (v8 FreezeBN logic)")
    
    def _ts(self):
        """æ—¶é—´æˆ³"""
        return datetime.now().strftime('%H:%M:%S')
    
    def add_update(self, grad_vector: torch.Tensor, n_samples: int, metrics: Optional[Dict] = None, bits_up: Optional[float] = None, quant_params: Optional[Dict] = None):
        """æ·»åŠ å®¢æˆ·ç«¯æ›´æ–°åˆ°ç¼“å†²åŒº"""
        self.update_buffer.append({'grad_vector': grad_vector, 'quant_params': quant_params})
        self.sample_counts.append(n_samples)
        if metrics:
            self.metrics_buffer.append(metrics)
        if bits_up is not None:
            self.bits_up_buffer.append(bits_up)

        waiting = self.config.clients_per_round - len(self.update_buffer)
        print(f"[{self._ts()}] ğŸ“¥ æ”¶åˆ°å®¢æˆ·ç«¯æ›´æ–° ({len(self.update_buffer)}/{self.config.clients_per_round})")

        if len(self.update_buffer) >= self.config.clients_per_round:
            self._aggregate_and_advance()
    
    def _aggregate_and_advance(self):
        """èšåˆæ›´æ–°å¹¶æ¨è¿›åˆ°ä¸‹ä¸€è½®"""
        print(f"\n{'='*70}")
        print(f"[{self._ts()}] ğŸ”„ èšåˆ Round {self.current_round}")
        print(f"{'='*70}")

        if self.config.aggregation_mode == "flq-fed" or self.config.aggregation_mode == "fedavg":
            # ç»Ÿä¸€å¤„ç†ï¼šè§£å‹ -> èšåˆ -> æ›´æ–°
            grad_vectors = []
            
            for item in self.update_buffer:
                vec = item['grad_vector'] # Tensor
                q_params = item['quant_params']
                
                if q_params:
                    # åé‡åŒ–
                    dequantized = FLQCompressor.dequantize(
                        vec,
                        q_params['scale'],
                        q_params['zero_point'],
                        q_params['bits']
                    )
                    grad_vectors.append(dequantized)
                else:
                    grad_vectors.append(vec)
            
            # èšåˆæ¢¯åº¦å·®å¼‚ (avg_update)
            # v8 é€»è¾‘: Global LR = 1.0 (æ—  momentum)
            # global_new = global_old + 1.0 * avg(local - global)
            aggregated_grad = fedavg_aggregate(grad_vectors, self.sample_counts)
            
            # æ›´æ–°å…¨å±€æ¨¡å‹
            # state_dict_new = state_dict_old + aggregated_grad
            # æ³¨æ„ï¼šéœ€å°† aggregated_grad æ˜ å°„å› state_dict ç»“æ„
            
            # å…ˆå±•å¹³ old global
            flat_global = state_dict_to_vector(self.global_state) # åªåŒ…å« float å‚æ•°
            
            # æ›´æ–°
            flat_new_global = flat_global + aggregated_grad.cpu()
            
            # é‡æ„ state_dict
            self.global_state = vector_to_state_dict(flat_new_global, self.global_state)
            
            # æ¸…ç†
            del grad_vectors, aggregated_grad, flat_global, flat_new_global
            gc.collect()

        else:
            print(f"âš ï¸  æœªçŸ¥çš„èšåˆæ¨¡å¼: {self.config.aggregation_mode}, è·³è¿‡èšåˆ")

        # æ›´æ–° last_global_state (ç”¨äºä¸‹è½®)
        # self.last_global_state = {k: v.clone() for k, v in self.global_state.items()}

        # è®¡ç®—é€šä¿¡é‡
        _, bits_down_mb = compute_model_size(self.global_state, bits=32)
        self.bits_down_per_round = bits_down_mb * (1024 ** 2) * 8

        # èšåˆæŒ‡æ ‡
        round_metrics = {}
        if self.metrics_buffer:
            # ç®€å•çš„æ•°å€¼å¹³å‡
            keys = set()
            for m in self.metrics_buffer: keys.update(m.keys())
            
            for key in keys:
                values = [m.get(key, 0.0) for m in self.metrics_buffer]
                round_metrics[key] = sum(values) / len(values)
        
        if self.bits_up_buffer:
            round_metrics['bits_up_total_round'] = sum(self.bits_up_buffer)
        round_metrics['bits_down_total_round'] = self.bits_down_per_round

        self.round_metrics[self.current_round] = round_metrics
        print(f"ğŸ“Š å¹³å‡ Loss: {round_metrics.get('final_loss', 0.0):.4f}")
        print(f"â¬†ï¸  æœ¬è½®ä¸Šä¼ æ€»æ¯”ç‰¹: {round_metrics.get('bits_up_total_round', 0.0) / 1e6:.2f} Mb")

        # ä¿å­˜checkpoint
        save_dir = Path(self.config.server_save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        if (self.current_round + 1) % 5 == 0:
            checkpoint_path = save_dir / f"global_round_{self.current_round + 1}.pt"
            torch.save(self.global_state, checkpoint_path)
            print(f"ğŸ’¾ Checkpoint: {checkpoint_path}")

        # ç»Ÿè®¡æ—¶é—´
        round_time = (datetime.now() - self.round_start_time).total_seconds() if self.round_start_time else 0
        print(f"â±ï¸  è½®æ¬¡æ—¶é—´: {round_time:.1f}s")
        print(f"{'='*70}\n")

        # é‡ç½®ç¼“å†²åŒº
        self.update_buffer.clear()
        self.sample_counts.clear()
        self.metrics_buffer.clear()
        self.bits_up_buffer.clear()
        
        self.current_round += 1
        self.round_start_time = datetime.now()

        if self.current_round >= self.config.rounds:
            self.training_done = True
            print(f"ğŸ‰ æ‰€æœ‰è®­ç»ƒè½®æ¬¡å·²å®Œæˆï¼")
            self._save_metrics_to_csv()
    
    def get_global_model(self) -> tuple:
        """è·å–å…¨å±€æ¨¡å‹"""
        return self.global_state, self.current_round, self.training_done

    def _save_metrics_to_csv(self):
        import csv
        csv_path = Path(self.config.server_save_dir) / "training_metrics.csv"
        csv_path.parent.mkdir(parents=True, exist_ok=True)
        with open(csv_path, 'w', newline='') as f:
            writer = csv.writer(f)
            if not self.round_metrics:
                writer.writerow(['round'])
                return
            first = next(iter(self.round_metrics.values()))
            headers = ['round'] + sorted(first.keys())
            writer.writerow(headers)
            for r, m in self.round_metrics.items():
                writer.writerow([r] + [m.get(k, '') for k in sorted(first.keys())])
        print(f"\nğŸ“Š è®­ç»ƒæŒ‡æ ‡å·²ä¿å­˜åˆ°: {csv_path}")

    def get_current_metrics(self) -> Dict:
        if self.current_round > 0 and (self.current_round - 1) in self.round_metrics:
            return self.round_metrics[self.current_round - 1]
        return {}


# ==================== FastAPI åº”ç”¨ ====================

def create_app(config: Config, initial_model) -> FastAPI:
    app = FastAPI(title="FLQ-Fed Server v8")
    state = ServerState(config, initial_model)
    
    @app.get("/")
    def root():
        return {"message": "FLQ-Fed Server", "version": "v8-FreezeBN"}
    
    @app.get("/status", response_model=StatusResponse)
    def get_status():
        curr = state.get_current_metrics()
        rt = (datetime.now() - state.round_start_time).total_seconds() if state.round_start_time else 0.0
        return StatusResponse(
            current_round=state.current_round,
            total_rounds=state.config.rounds,
            training_done=state.training_done,
            buffered_updates=len(state.update_buffer),
            clients_per_round=state.config.clients_per_round,
            waiting_for=state.config.clients_per_round - len(state.update_buffer),
            aggregation_mode=state.config.aggregation_mode,
            avg_map50=curr.get('map50'),
            avg_loss=curr.get('final_loss'),
            round_time=rt,
            bits_down_total_round=curr.get('bits_down_total_round'),
            bits_up_total_round=curr.get('bits_up_total_round')
        )
    
    @app.get("/global")
    def get_global():
        gs, rid, done = state.get_global_model()
        # åºåˆ—åŒ– state_dict (è½¬ä¸º list ä»¥ä¾¿ JSON ä¼ è¾“)
        serialized = {k: v.tolist() for k, v in gs.items()}
        return {
            "state_dict": serialized,
            "round": rid,
            "done": done
        }
    
    @app.post("/update")
    def receive_update(request: UpdateRequest):
        if state.training_done:
            return {"success": True, "done": True}
        
        # è½¬æ¢ grad_vector ä¸º tensor
        grad_vector = torch.tensor(request.grad_vector)
        
        state.add_update(
            grad_vector,
            request.n_samples,
            request.metrics,
            request.bits_up,
            request.quant_params
        )
        return {
            "success": True, 
            "round": state.current_round, 
            "done": state.training_done,
            "buffered": len(state.update_buffer)
        }
    
    return app


def start_server(config_path: Optional[str] = None):
    print("="*70)
    print("ğŸš€ FLQ-Fed è”é‚¦å­¦ä¹ æœåŠ¡å™¨ (v8)")
    print("="*70)
    
    config = Config(config_path)
    print(f"âœ… é…ç½®: {config}\n")
    
    # åˆå§‹åŒ–æ¨¡å‹
    from ultralytics import YOLO
    project_root = Path(__file__).parent.parent
    model_path = project_root / config.model_name
    
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    model = YOLO(str(model_path))
    
    # åˆå§‹åŒ–ç»“æ„ (NC)
    data_yaml = project_root / "data" / "client1" / "oil.yaml"
    if data_yaml.exists():
        import yaml
        with open(data_yaml) as f:
            data_cfg = yaml.safe_load(f)
        nc = data_cfg.get('nc', 80)
        from ultralytics.nn.tasks import DetectionModel
        model.model = DetectionModel(model.model.yaml, ch=3, nc=nc)
        print(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (nc={nc})\n")
    
    app = create_app(config, model)
    
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸŒ å¯åŠ¨æœåŠ¡å™¨: http://{config.server_host}:{config.server_port}")
    print(f"{'='*70}\n")
    
    uvicorn.run(
        app,
        host=config.server_host,
        port=config.server_port,
        log_level="warning"
    )

if __name__ == "__main__":
    start_server()

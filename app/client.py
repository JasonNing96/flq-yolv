"""
FLQ-Fed è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯
ç®€åŒ–ç‰ˆ - çº¿æ€§æµç¨‹ï¼Œæ˜“äºè°ƒè¯•
"""
import os
import time
import torch
import yaml
import requests
from pathlib import Path
from datetime import datetime
from typing import Optional, Any, Dict
from ultralytics import YOLO

from .config import Config
from .model_utils import (
    compute_model_size,
    quantize_vector, dequantize_vector,
    state_dict_to_vector, vector_to_state_dict,
    state_dict_to_grad_vector, grad_vector_to_state_dict,
    ErrorFeedback
)


# ==================== å…¨å±€é…ç½® ====================

PROJECT_ROOT = Path(__file__).parent.parent
CLIENT_ID = None
SERVER_URL = None
DATA_YAML = None
OUTPUT_DIR = None


# ==================== å·¥å…·å‡½æ•° ====================

def _ts():
    """æ—¶é—´æˆ³"""
    return datetime.now().strftime('%H:%M:%S')


def _log(msg: str):
    """æ—¥å¿—è¾“å‡º"""
    print(f"[{_ts()}] {msg}")


# ==================== æ ¸å¿ƒæµç¨‹ ====================

def pull_global_model(model: YOLO) -> tuple:
    """
    ä»æœåŠ¡å™¨æ‹‰å–å…¨å±€æ¨¡å‹
    
    Returns:
        current_round: å½“å‰è½®æ¬¡
        is_done: æ˜¯å¦å®Œæˆè®­ç»ƒ
        global_state_dict: å…¨å±€æ¨¡å‹çš„ state_dict
    """
    try:
        response = requests.get(f"{SERVER_URL}/global", timeout=10)
        response.raise_for_status()
        data = response.json()
        
        # ååºåˆ—åŒ– state_dict
        global_state_dict = {k: torch.tensor(v) for k, v in data['state_dict'].items()}
        
        # å¦‚æœæœåŠ¡å™¨ä¸‹å‘çš„æ˜¯é‡åŒ–æ¨¡å‹ï¼Œåˆ™éœ€è¦åé‡åŒ–
        downlink_quant_bits = data.get('downlink_quant_bits', 0)
        if downlink_quant_bits > 0:
            _log(f"ğŸ“¥ æœåŠ¡å™¨ä¸‹å‘ {downlink_quant_bits}-bit é‡åŒ–æ¨¡å‹ï¼Œè¿›è¡Œåé‡åŒ–...")
            global_vector = state_dict_to_vector(global_state_dict)
            # è¿™é‡Œå‡è®¾æœåŠ¡å™¨å·²ç»åé‡åŒ–å›å…¨ç²¾åº¦ï¼Œå®¢æˆ·ç«¯ç›´æ¥åŠ è½½å³å¯
            # å¦‚æœæœåŠ¡å™¨ä¸‹å‘çš„æ˜¯é‡åŒ–å€¼ï¼Œè¿™é‡Œéœ€è¦ dequantize_vector
            # ä½†ç›®å‰æœåŠ¡å™¨ç«¯æ˜¯å…ˆé‡åŒ–å†åé‡åŒ–ï¼Œæ‰€ä»¥å®¢æˆ·ç«¯ç›´æ¥åŠ è½½å³å¯
        
        model.model.load_state_dict(global_state_dict, strict=False)
        
        current_round = data['round']
        is_done = data['done']
        
        _log(f"ğŸ“¥ æ‹‰å–å…¨å±€æ¨¡å‹æˆåŠŸ (Round {current_round})")
        return current_round, is_done, global_state_dict
        
    except Exception as e:
        _log(f"âŒ æ‹‰å–æ¨¡å‹å¤±è´¥: {e}")
        raise


def train_local(model: YOLO, round_id: int, config: Config):
    """
    æœ¬åœ°è®­ç»ƒ
    
    Args:
        model: YOLOæ¨¡å‹
        round_id: å½“å‰è½®æ¬¡
        config: é…ç½®å¯¹è±¡
    """
    _log(f"ğŸ¯ å¼€å§‹æœ¬åœ°è®­ç»ƒ Round {round_id}...")
    
    try:
        results = model.train(
            data=DATA_YAML,
            epochs=config.local_epochs,
            batch=config.batch_size,
            imgsz=640,
            device=config.device,
            workers=config.workers,
            project=OUTPUT_DIR,
            name=f"round_{round_id}",
            exist_ok=True,
            verbose=config.verbose,
            val=config.enable_val,
            plots=config.enable_plots
        )
        
        # æå–å…³é”®æŒ‡æ ‡
        metrics = results.results_dict if hasattr(results, 'results_dict') else {}
        map50 = metrics.get('metrics/mAP50(B)', 0.0)
        
        _log(f"âœ… æœ¬åœ°è®­ç»ƒå®Œæˆ (mAP50: {map50:.3f})")
        return results
        
    except Exception as e:
        _log(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        raise


def push_update(
    model: YOLO,
    n_samples: int,
    round_id: int,
    train_results: Any,
    last_global_state: Dict[str, Any],
    config: Config,
    error_feedback_instance: Optional[ErrorFeedback] = None
):
    """
    ä¸Šä¼ æœ¬åœ°æ›´æ–°åˆ°æœåŠ¡å™¨
    
    Args:
        model: è®­ç»ƒåçš„æ¨¡å‹
        n_samples: æœ¬åœ°æ ·æœ¬æ•°
        round_id: å½“å‰è½®æ¬¡
        train_results: æœ¬åœ°è®­ç»ƒç»“æœå¯¹è±¡
        last_global_state: ä¸Šä¸€è½®çš„å…¨å±€æ¨¡å‹ state_dict
        config: é…ç½®å¯¹è±¡
        error_feedback_instance: è¯¯å·®åé¦ˆå®ä¾‹
    """
    try:
        local_state_dict = model.model.state_dict()
        
        # è®¡ç®—æ¢¯åº¦å·®å¼‚
        grad_vector = state_dict_to_grad_vector(local_state_dict, last_global_state)
        
        bits_up = 0.0
        quant_params = None
        
        if config.aggregation_mode == "flq-fed" and config.quant_enabled:
            _log(f"ğŸ—œï¸  è¿›è¡Œ {config.quant_bits}-bit é‡åŒ–...")
            
            if error_feedback_instance and config.error_feedback_enabled:
                quantized_grad_vector, scale, zero_point = \
                    error_feedback_instance.compress_with_feedback(grad_vector, bits=config.quant_bits)
            else:
                quantized_grad_vector, scale, zero_point = \
                    quantize_vector(grad_vector, bits=config.quant_bits)
            
            # åºåˆ—åŒ–é‡åŒ–åçš„æ¢¯åº¦å‘é‡
            serialized_grad_vector = quantized_grad_vector.cpu().tolist()
            
            # è®¡ç®—ä¸Šä¼ æ¯”ç‰¹æ•°
            num_params = grad_vector.numel()
            bits_up = num_params * config.quant_bits
            
            quant_params = {
                "scale": scale,
                "zero_point": zero_point,
                "bits": config.quant_bits
            }
            
            _log(f"âœ… é‡åŒ–å®Œæˆï¼Œä¸Šä¼  {config.quant_bits}-bit æ¢¯åº¦å·®å¼‚ã€‚")
        else:
            # FedAvg æˆ–æœªå¯ç”¨é‡åŒ–ï¼Œä¸Šä¼ å…¨ç²¾åº¦æ¢¯åº¦å·®å¼‚
            _log("â¬†ï¸  ä¸Šä¼ å…¨ç²¾åº¦æ¢¯åº¦å·®å¼‚...")
            serialized_grad_vector = grad_vector.cpu().tolist()
            
            # è®¡ç®—ä¸Šä¼ æ¯”ç‰¹æ•° (32-bit æµ®ç‚¹æ•°)
            num_params = grad_vector.numel()
            bits_up = num_params * 32
        
        # æå–è®­ç»ƒæŒ‡æ ‡
        metrics = {}
        if hasattr(train_results, 'results_dict'):
            results_dict = train_results.results_dict
            metrics['map50'] = results_dict.get('metrics/mAP50(B)', 0.0)
            metrics['map'] = results_dict.get('metrics/mAP50-95(B)', 0.0)
            metrics['precision'] = results_dict.get('metrics/precision(B)', 0.0)
            metrics['recall'] = results_dict.get('metrics/recall(B)', 0.0)
            metrics['loss'] = results_dict.get('train/box_loss', 0.0) + \
                              results_dict.get('train/cls_loss', 0.0) + \
                              results_dict.get('train/dfl_loss', 0.0)
        
        # å‘é€æ›´æ–°
        payload = {
            "client_id": CLIENT_ID,
            "grad_vector": serialized_grad_vector,
            "n_samples": n_samples,
            "round_id": round_id,
            "metrics": metrics,
            "bits_up": bits_up,
            "quant_params": quant_params
        }
        
        _log(f"ğŸ“¤ ä¸Šä¼ æœ¬åœ°æ›´æ–° (mAP50: {metrics.get('map50', 0.0):.3f}, Bits Up: {bits_up / (1024**2) / 8:.2f} MB)...")
        response = requests.post(f"{SERVER_URL}/update", json=payload, timeout=60)
        if not response.ok:
            _log(f"âš ï¸  ä¸Šä¼ å¤±è´¥è¯¦æƒ…: {response.text}")
        response.raise_for_status()
        
        result = response.json()
        _log(f"âœ… ä¸Šä¼ æˆåŠŸ (Round {result['round']}, ç¼“å†²={result['buffered']})")
        
        return result
        
    except Exception as e:
        _log(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
        raise


def count_samples(data_yaml_path: str) -> int:
    """ç»Ÿè®¡æœ¬åœ°è®­ç»ƒæ ·æœ¬æ•°"""
    with open(data_yaml_path) as f:
        cfg = yaml.safe_load(f)
    
    # ç»Ÿè®¡è®­ç»ƒé›†å›¾ç‰‡æ•°
    train_path = Path(cfg['path']) / cfg['train']
    if train_path.exists():
        return len(list(train_path.glob('*.jpg'))) + len(list(train_path.glob('*.png')))
    return 0


# ==================== ä¸»æµç¨‹ ====================

def start_client(client_id: int, server_url: str = None, config_path: Optional[str] = None):
    """
    å¯åŠ¨è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯
    
    Args:
        client_id: å®¢æˆ·ç«¯ID (1, 2, 3, ...)
        server_url: æœåŠ¡å™¨åœ°å€ï¼ˆå¯é€‰ï¼‰
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    global CLIENT_ID, SERVER_URL, DATA_YAML, OUTPUT_DIR
    
    print("="*70)
    print(f"ğŸš€ FLQå®¢æˆ·ç«¯ #{client_id}")
    print("="*70)
    
    # åŠ è½½é…ç½®
    config = Config(config_path)
    
    # è®¾ç½®å…¨å±€å˜é‡
    CLIENT_ID = client_id
    SERVER_URL = server_url or f"http://{config.server_host}:{config.server_port}"
    DATA_YAML = str(PROJECT_ROOT / "data" / f"client{client_id}" / "oil.yaml")
    OUTPUT_DIR = str(PROJECT_ROOT / "outputs" / f"client{client_id}" / "runs")
    
    _log(f"ğŸŒ æœåŠ¡å™¨: {SERVER_URL}")
    _log(f"ğŸ“ æ•°æ®: {DATA_YAML}")
    _log(f"ğŸ“‚ è¾“å‡º: {OUTPUT_DIR}")
    _log(f"ğŸ–¥ï¸  è®¾å¤‡: {config.device}")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not os.path.exists(DATA_YAML):
        _log(f"âŒ æ•°æ®é…ç½®ä¸å­˜åœ¨: {DATA_YAML}")
        _log(f"ğŸ’¡ æç¤º: è¯·å…ˆè¿è¡Œ python scripts/split_dataset.py")
        return
    
    # ç»Ÿè®¡æ ·æœ¬æ•°
    n_samples = count_samples(DATA_YAML)
    _log(f"ğŸ“Š æœ¬åœ°æ ·æœ¬æ•°: {n_samples}\n")
    
    # åˆå§‹åŒ–æ¨¡å‹
    _log("ğŸ“¦ åˆå§‹åŒ–æ¨¡å‹...")
    model_path = PROJECT_ROOT / config.model_name
    model = YOLO(str(model_path))
    
    # è¯»å–ç±»åˆ«æ•°
    with open(DATA_YAML) as f:
        data_cfg = yaml.safe_load(f)
    nc = data_cfg.get('nc', 80)
    
    from ultralytics.nn.tasks import DetectionModel
    model.model = DetectionModel(model.model.yaml, ch=3, nc=nc)
    _log(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ (nc={nc})\n")
    
    # ä¸»å¾ªç¯
    last_round = -1
    last_global_state = None
    error_feedback_instance = ErrorFeedback() if config.error_feedback_enabled else None
    
    while True:
        try:
            # 1. æ‹‰å–å…¨å±€æ¨¡å‹
            current_round, is_done, global_state_dict = pull_global_model(model)
            last_global_state = global_state_dict # ä¿å­˜å½“å‰å…¨å±€æ¨¡å‹ï¼Œç”¨äºè®¡ç®—æ¢¯åº¦å·®å¼‚
            
            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if is_done:
                print("\n" + "="*70)
                _log("ğŸ‰ æ‰€æœ‰è”é‚¦è®­ç»ƒè½®æ¬¡å·²å®Œæˆï¼")
                _log(f"ğŸ“ è®­ç»ƒç»“æœ: {OUTPUT_DIR}")
                print("="*70)
                break
            
            # æ£€æŸ¥æ˜¯å¦å·²è®­ç»ƒè¿‡å½“å‰è½®æ¬¡
            if current_round == last_round:
                _log("â³ ç­‰å¾…æœåŠ¡å™¨èšåˆ...")
                time.sleep(5)
                continue
            
            # 2. æœ¬åœ°è®­ç»ƒ
            train_results = train_local(model, current_round, config)
            
            # 3. ä¸Šä¼ æ›´æ–°
            response = push_update(model, n_samples, current_round, train_results, last_global_state, config, error_feedback_instance)
            
            # æ›´æ–°è½®æ¬¡è®°å½•
            last_round = current_round
            
            # æ£€æŸ¥æœåŠ¡å™¨è¿”å›çš„å®Œæˆæ ‡å¿—
            if response.get("done", False):
                print("\n" + "="*70)
                _log("ğŸ‰ è”é‚¦è®­ç»ƒå®Œæˆï¼ˆæœåŠ¡å™¨é€šçŸ¥ï¼‰")
                print("="*70)
                break
            
            _log(f"âœ… Round {current_round} å®Œæˆ\n")
        
        except KeyboardInterrupt:
            _log("âš ï¸  ç”¨æˆ·ä¸­æ–­")
            break
        
        except Exception as e:
            _log(f"âŒ é”™è¯¯: {e}")
            _log("ğŸ”„ 5ç§’åé‡è¯•...")
            time.sleep(5)


if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python -m app.client <client_id>")
        sys.exit(1)
    
    start_client(int(sys.argv[1]))


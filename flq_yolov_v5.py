#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
FLQ-YOLOv5 è”é‚¦è®­ç»ƒè„šæœ¬ (Stateless Version)
----------------------------------------------------------------
- æ ¸å¿ƒä¿®å¤: é‡‡ç”¨ "Stateless" è®¾è®¡ã€‚ManualClientTrainer ä¸å†æŒæœ‰æ¨¡å‹å®ä¾‹ã€‚
- æ˜¾å­˜ç®¡ç†: æ¯æ¬¡ train_epoch åŠ¨æ€åŠ è½½æ¨¡å‹ï¼Œç»“æŸåå¼ºåˆ¶é”€æ¯å¹¶ GCï¼Œç¡®ä¿æ˜¾å­˜å½’é›¶ã€‚
- è§£å†³æŠ¥é”™: å½»åº•æ ¹æ²» CUDA OOM å¯¼è‡´çš„ Device Mismatch é—®é¢˜ã€‚
----------------------------------------------------------------
"""

# ================= è¡¥ä¸: ä¿®å¤ Torch ç‰ˆæœ¬å…¼å®¹æ€§ =================
import torch
try:
    _ = torch.OutOfMemoryError
except AttributeError:
    torch.OutOfMemoryError = RuntimeError
# ===========================================================

import argparse
import copy
import json
import random
import os
import time
import shutil
import gc  # <--- æ–°å¢ï¼šåƒåœ¾å›æ”¶æ¨¡å—
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from types import SimpleNamespace  # <--- æ–°å¢è¿™è¡Œå¼•ç”¨

import numpy as np
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import autocast, GradScaler

# Ultralytics ç»„ä»¶
from ultralytics import YOLO
from ultralytics.utils import DEFAULT_CFG
from ultralytics.cfg import get_cfg
from ultralytics.data import build_yolo_dataset, build_dataloader
from ultralytics.utils.loss import v8DetectionLoss
from ultralytics.data.utils import check_det_dataset

# ====================== 1. åŸºç¡€å·¥å…· & DIL ======================


def seed_everything(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def save_json(obj, path: Path) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)


def sample_dil_bandwidth() -> float:
    return random.uniform(2.0, 10.0)


def sample_dil_loss_ratio() -> float:
    return random.uniform(0.0, 0.2)


def apply_DIL_fluctuation(bits: float) -> float:
    bw_mbps = sample_dil_bandwidth()
    max_bits = bw_mbps * 1e6
    loss_ratio = sample_dil_loss_ratio()
    bits_after_loss = bits * (1.0 - loss_ratio)
    bits_limited = min(bits_after_loss, max_bits)
    return float(bits_limited)

# ====================== 2. æ ¸å¿ƒç®—æ³•: FLQ å‹ç¼©å™¨ ======================


class FLQCompressor:
    def __init__(self, device):
        self.device = device
        self.local_error: Optional[torch.Tensor] = None

    def flatten_params(self, state_dict: Dict) -> torch.Tensor:
        tensors = [v.float().to(self.device)
                   for v in state_dict.values() if v.dtype.is_floating_point]
        if not tensors:
            return torch.tensor([], device=self.device)
        return torch.cat([t.view(-1) for t in tensors])

    def reconstruct_state_dict(self, flat_vec: torch.Tensor, template_sd: Dict) -> Dict:
        out = {}
        offset = 0
        flat_vec = flat_vec.to(self.device)
        for k, v in template_sd.items():
            if v.dtype.is_floating_point:
                numel = v.numel()
                out[k] = flat_vec[offset: offset +
                                  numel].view(v.shape).to(v.dtype).cpu()
                offset += numel
            else:
                out[k] = v.clone().cpu()
        return out

    def quantize_update(self, delta_vec: torch.Tensor, bits: int) -> Tuple[torch.Tensor, int]:
        num_params = delta_vec.numel()
        if self.local_error is None:
            self.local_error = torch.zeros_like(delta_vec)
        target = delta_vec + self.local_error

        if bits >= 32:
            self.local_error.zero_()
            return target, num_params * 32

        if bits == 1:
            scale = target.abs().mean()
            if scale < 1e-8:
                scale = 1e-8
            sign = torch.sign(target)
            sign[sign == 0] = 1.0
            quantized = sign * scale
            self.local_error = target - quantized
            return quantized, num_params + 32
        else:
            mn, mx = target.min(), target.max()
            scale = (mx - mn) / (2**bits - 1 + 1e-8)
            zero = -mn / (scale + 1e-8)
            q = torch.clamp(torch.round(target / scale + zero), 0, 2**bits - 1)
            dq = (q - zero) * scale
            self.local_error = target - dq
            return dq, num_params * bits + 32

# ====================== 3. è®­ç»ƒå†…æ ¸: Stateless Manual Trainer ======================


class ManualClientTrainer:
    """
    æ— çŠ¶æ€è®­ç»ƒå™¨ï¼šä¸åœ¨ __init__ ä¸­ä¿ç•™æ¨¡å‹ï¼Œåªåœ¨ train_epoch ä¸­ä¸´æ—¶åˆ›å»ºå¹¶é”€æ¯ã€‚
    """

    def __init__(self, model_path: str, data_yaml: Path, device: str, batch: int, imgsz: int):
        self.device = device
        self.data_yaml = data_yaml
        self.model_path = model_path  # åªå­˜è·¯å¾„ï¼Œä¸åŠ è½½æ¨¡å‹å¯¹è±¡
        self.batch = batch
        self.imgsz = imgsz

        # --- DataLoader (ä¿æŒæŒä¹…åŒ–ï¼Œå› ä¸º DataLoader é‡å»ºå¾ˆæ…¢ä¸”ä¸å æ˜¾å­˜) ---
        cfg = get_cfg(DEFAULT_CFG)
        cfg.data = str(data_yaml)
        cfg.imgsz = imgsz
        cfg.batch = batch

        data_info = check_det_dataset(str(data_yaml))
        train_path = data_info['train']

        self.dataset = build_yolo_dataset(
            cfg, train_path, batch, data_info, mode="train", rect=False, stride=32
        )
        # å¼ºåˆ¶ workers=0 é¿å…å¤šè¿›ç¨‹æ­»é”
        self.loader = build_dataloader(
            self.dataset, batch, workers=0, shuffle=True, rank=-1)

        # å‹ç¼©å™¨æ˜¯è½»é‡çº§çš„ï¼Œå¯ä»¥ä¿ç•™
        self.compressor = FLQCompressor(device)

    def train_epoch(self, global_sd: Dict, local_epochs: int, lr: float, momentum: float) -> Tuple[Dict, dict, dict]:
        """æ‰§è¡Œæœ¬åœ°è®­ç»ƒ - æ˜¾å­˜å®‰å…¨ç‰ˆ"""

        # 1. åŠ¨æ€åˆ›å»ºæ¨¡å‹ (Fresh Load)
        # è¿™ç¡®ä¿äº†æ²¡æœ‰ä»»ä½•ä¹‹å‰çš„ç¼“å­˜æ®‹ç•™
        temp_wrapper = YOLO(self.model_path)
        model = temp_wrapper.model

        # ================= å…³é”®ä¿®å¤ï¼šDict è½¬ Namespace =================
        # è§£å†³ AttributeError: 'dict' object has no attribute 'box'
        if hasattr(model, 'args') and isinstance(model.args, dict):
            model.args = SimpleNamespace(**model.args)
        # ===========================================================
        
        # åŠ è½½æƒé‡ & ç§»è‡³ GPU
        model.load_state_dict(global_sd)
        model.to(self.device)
        model.train()

        #=================== å…³é”®ä¿®å¤ï¼šè§£å†»æ‰€æœ‰å‚æ•° ===================
        # è§£å†³ RuntimeError: element 0 of tensors does not require grad
        for param in model.parameters():
            param.requires_grad = True
        # ================
        
        # 2. åŠ¨æ€åˆ›å»º Loss & Scaler
        loss_fn = v8DetectionLoss(model)
        
        # =================== ç»ˆæä¿®å¤ï¼šç›´æ¥ä¿®æ­£ Loss å¯¹è±¡çš„è¶…å‚æ•° ===================
        # æœ‰æ—¶å€™ v8DetectionLoss ä¼šæ·±æ‹·è´ argsï¼Œå¯¼è‡´ä¸Šé¢å¯¹ model.args çš„ä¿®æ”¹æ²¡ç”Ÿæ•ˆ
        # æˆ–è€… model.args æœ¬èº«è¢« Ultralytics å†…éƒ¨é€»è¾‘é‡ç½®äº†
        if hasattr(loss_fn, 'hyp'):
            # ç¡®ä¿ hyp æ˜¯ä¸ª Namespace
            if isinstance(loss_fn.hyp, dict):
                loss_fn.hyp = SimpleNamespace(**loss_fn.hyp)
            
            # æš´åŠ›æ³¨å…¥é»˜è®¤å€¼
            if not hasattr(loss_fn.hyp, 'box'): loss_fn.hyp.box = 7.5
            if not hasattr(loss_fn.hyp, 'cls'): loss_fn.hyp.cls = 0.5
            if not hasattr(loss_fn.hyp, 'dfl'): loss_fn.hyp.dfl = 1.5
        # =======================================================================

        if hasattr(loss_fn, 'proj'):
            loss_fn.proj = loss_fn.proj.to(self.device)

        scaler = GradScaler()
        # === å…³é”®è°ƒæ•´ï¼šé€‚åº” Stateless è®­ç»ƒ ===
        # ä¿æŒåŸå§‹ LRï¼Œä½†ç§»é™¤ Momentum ä»¥é˜²æ­¢åœ¨é‡ç½® Optimizer æ—¶å‘ç”Ÿéœ‡è¡
        optimizer = optim.SGD(model.parameters(), lr=lr,
                              momentum=0.0, weight_decay=5e-4)

        loss_stats = {"box": [], "cls": [], "dfl": []}

        # --- è®­ç»ƒå¾ªç¯ ---
        for epoch in range(local_epochs):
            for batch in self.loader:
                # é¢„å¤„ç†
                batch['img'] = batch['img'].to(
                    self.device, non_blocking=True).float() / 255.0
                for k in batch:
                    if k != 'img' and isinstance(batch[k], torch.Tensor):
                        batch[k] = batch[k].to(self.device)

                optimizer.zero_grad()

                # AMP å‰å‘
                with autocast(enabled=True):
                    preds = model(batch['img'])
                    loss, loss_items = loss_fn(preds, batch)

                # AMP åå‘
                scaler.scale(loss).backward()
                scaler.unscale_(optimizer)
                nn.utils.clip_grad_norm_(model.parameters(), 10.0)
                scaler.step(optimizer)
                scaler.update()

                loss_stats["box"].append(loss_items[0].item())
                loss_stats["cls"].append(loss_items[1].item())
                loss_stats["dfl"].append(loss_items[2].item())

        # --- è®­ç»ƒç»“æŸï¼šæå–ç»“æœ ---
        final_sd = {k: v.cpu() for k, v in model.state_dict().items()}

        # ================= æ¿€è¿›çš„æ˜¾å­˜æ¸…ç† =================
        # 1. æ‰‹åŠ¨åˆ é™¤å¼•ç”¨
        del model
        del temp_wrapper
        del loss_fn
        del optimizer
        del scaler

        # 2. å¼ºåˆ¶åƒåœ¾å›æ”¶ (æ¸…é™¤ Python å¯¹è±¡)
        gc.collect()

        # 3. æ¸…ç©º PyTorch ç¼“å­˜ (æ¸…é™¤ GPU ç¢ç‰‡)
        torch.cuda.empty_cache()
        # ===============================================

        metadata = {
            "final_loss": np.mean(loss_stats["box"]) if loss_stats["box"] else 0.0,
        }
        return final_sd, loss_stats, metadata

# ====================== 4. ä¸»æµç¨‹ ======================


def run_federated_flq(
    client_yaml_list: List[Path],
    val_yaml: Path,
    model_path: Path,
    rounds: int,
    local_epochs: int,
    bits: int,
    batch: int,
    imgsz: int,
    device: str,
    workers: int,
    out_dir: Path,
) -> None:
    seed_everything(42)
    out_dir.mkdir(parents=True, exist_ok=True)

    if torch.cuda.is_available() and device != 'cpu':
        if device.isdigit():
            device = f"cuda:{device}"
    else:
        device = 'cpu'

    print(f"ğŸš€ FLQ-YOLOv5 (Stateless Fixed) | Device: {device} | Bits: {bits}")

    # 1. åˆå§‹åŒ– & Warmup
    print("   [Init] Adapting model head (Warmup)...")
    warmup_dir = out_dir / "warmup_temp"

    # ä¸´æ—¶åˆ›å»ºæ¨¡å‹ç”¨äº Warmup
    init_model = YOLO(str(model_path))
    try:
        # ä¿®æ­£ï¼šWarmup ä¹Ÿä½¿ç”¨ GPUï¼Œé¿å… Ultralytics è®¾ç½® CUDA_VISIBLE_DEVICES=-1 æ±¡æŸ“ç¯å¢ƒ
        init_model.train(
            data=str(val_yaml), epochs=1, imgsz=imgsz, batch=batch,
            device=device, project=str(warmup_dir), name="init_run",
            exist_ok=True, plots=False, save=True, val=False, verbose=False
        )
    except Exception as e:
        print(f"   [Init] Warmup passed: {e}")
    
    # === å…³é”®ä¿®å¤ï¼šæ¸…ç† Ultralytics å¯èƒ½æ®‹ç•™çš„ç¯å¢ƒå˜é‡ ===
    if "CUDA_VISIBLE_DEVICES" in os.environ:
        os.environ.pop("CUDA_VISIBLE_DEVICES")
    # ==================================================

    warmup_pt = warmup_dir / "init_run/weights/last.pt"
    adapted_pt = out_dir / "init_adapted.pt"
    model_path_to_use = model_path

    if warmup_pt.exists():
        shutil.copy(str(warmup_pt), str(adapted_pt))
        model_path_to_use = adapted_pt
        # é‡æ–°åŠ è½½ä»¥è·å–æ­£ç¡®ç»“æ„
        del init_model
        init_model = YOLO(str(adapted_pt))
    else:
        print("   [Warning] Warmup failed, using original model.")

    # è·å–åˆå§‹æƒé‡
    global_sd = {k: v.cpu().clone()
                 for k, v in init_model.model.state_dict().items()}
    template_sd = copy.deepcopy(global_sd)

    # === å…³é”®ï¼šç”¨å®Œç«‹åˆ»åˆ é™¤ init_model ===
    del init_model
    gc.collect()
    if warmup_dir.exists():
        try:
            shutil.rmtree(warmup_dir)
        except:
            pass
    # ===================================

    # 2. åˆå§‹åŒ– Clients (åªä¼ è·¯å¾„ï¼Œä¸ä¼ å¯¹è±¡)
    client_trainers = []
    for yaml_path in client_yaml_list:
        trainer = ManualClientTrainer(
            str(model_path_to_use), yaml_path, device, batch, imgsz)
        client_trainers.append(trainer)

    server_helper = FLQCompressor(device)
    # server_momentum_buffer = None # ç§»é™¤åŠ¨é‡bufferåˆå§‹åŒ–
    log = {"round": [], "mAP50": [], "mAP50-95": [],
           "box_loss": [], "bits_up_raw": [], "bits_up_dil": []}
    
    # è¯¦ç»†æ—¥å¿—è®°å½•
    client_details = {i: {"box_loss": [], "grad_scale": []} for i in range(len(client_yaml_list))}

    # 3. è”é‚¦å¾ªç¯
    for r in range(rounds):
        print(f"\n========== Round {r} / {rounds - 1} ==========")
        t_start = time.time()
        cur_lr = 0.01 * (0.98 ** r)

        client_updates_dense = []
        round_box_loss = 0.0
        bits_up_raw_total = 0.0
        bits_up_dil_total = 0.0

        # --- A. å®¢æˆ·ç«¯è®­ç»ƒ ---
        for i, trainer in enumerate(client_trainers):
            local_sd, loss_stats, meta = trainer.train_epoch(
                global_sd, local_epochs, lr=cur_lr, momentum=0.937)

            flat_global = server_helper.flatten_params(global_sd).to(device)
            flat_local = trainer.compressor.flatten_params(local_sd).to(device)
            delta = flat_local - flat_global

            q_delta, bit_cost = trainer.compressor.quantize_update(delta, bits)
            client_updates_dense.append(q_delta)
            
            scale = q_delta.abs().mean().item()
            client_details[i]["box_loss"].append(meta["final_loss"])
            client_details[i]["grad_scale"].append(scale)

            bits_up_raw_total += bit_cost
            bits_up_dil_total += apply_DIL_fluctuation(bit_cost)

            avg_loss = np.mean(loss_stats["box"]) if loss_stats["box"] else 0
            round_box_loss += avg_loss

            if i == 0:
                print(
                    f"   [Client {i}] Loss: {avg_loss:.4f} | Scale: {scale:.6f}")

        round_box_loss /= len(client_trainers)

        # --- B. æœåŠ¡å™¨èšåˆï¼ˆä¿®æ­£ç‰ˆï¼šçº¯ FedAvgï¼Œæ— æœåŠ¡å™¨åŠ¨é‡ï¼‰ ---
        print("   [Server] Aggregating...")
        stack_updates = torch.stack(client_updates_dense)
        avg_update = stack_updates.mean(dim=0)

        # å¯é€‰ï¼šå¦‚æœæ‹…å¿ƒæ­¥é•¿è¿‡å¤§ï¼Œå¯ä¹˜ä¸€ä¸ª global_lrï¼Œä¾‹å¦‚ 1.0
        # è¿™é‡Œæˆ‘ä»¬å…ˆä¿æŒæœ€åŸå§‹çš„ FedAvg
        
        # ç§»é™¤æ‰€æœ‰åŠ¨é‡é€»è¾‘
        # if server_momentum_buffer is None: ...
        # server_momentum_buffer = ...

        flat_global_new = server_helper.flatten_params(
            global_sd).to(device) + avg_update
        global_sd = server_helper.reconstruct_state_dict(
            flat_global_new, template_sd)

        # --- C. è¯„ä¼° (åŠ¨æ€åŠ è½½æ¨¡å¼) ---
        print("   [Server] Evaluating...")
        metrics = {"mAP50": 0, "mAP50-95": 0}
        try:
            torch.cuda.empty_cache()
            # åŠ¨æ€åŠ è½½è¯„ä¼°æ¨¡å‹
            val_model = YOLO(str(model_path_to_use))
            val_model.model.load_state_dict(global_sd)

            # æ¢å¤ä½¿ç”¨ GPU (device) è¿›è¡Œè¯„ä¼°
            results = val_model.val(
                data=str(val_yaml), batch=batch, device=device,
                verbose=False, plots=False
            )
            metrics["mAP50"] = results.results_dict.get(
                "metrics/mAP50(B)", 0.0)
            metrics["mAP50-95"] = results.results_dict.get(
                "metrics/mAP50-95(B)", 0.0)

            # è¯„ä¼°å®Œç«‹åˆ»é”€æ¯
            del val_model
            gc.collect()

        except Exception as e:
            print(f"   [Warning] Eval failed: {e}")

        torch.cuda.empty_cache()

        # --- D. æ—¥å¿— ---
        log["round"].append(r)
        log["mAP50"].append(metrics["mAP50"])
        log["mAP50-95"].append(metrics["mAP50-95"])
        log["box_loss"].append(round_box_loss)
        log["bits_up_raw"].append(bits_up_raw_total)
        log["bits_up_dil"].append(bits_up_dil_total)

        save_json(log, out_dir / "flq_log.json")
        # ä¿å­˜ Client è¯¦ç»†æ—¥å¿—
        save_json(client_details, out_dir / "client_details.json")
        
        print(
            f"   [Result] mAP50: {metrics['mAP50']:.4f} | Loss: {round_box_loss:.4f} | Time: {time.time()-t_start:.1f}s")

    torch.save(global_sd, out_dir / "global_last.pt")
    print(f"\nè®­ç»ƒå®Œæˆ. ç»“æœä¿å­˜åœ¨: {out_dir}")


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser()
    p.add_argument("--clients", type=str, nargs="+", required=True)
    p.add_argument("--val-data", type=str, required=True)
    p.add_argument("--model", type=str, required=True)
    p.add_argument("--rounds", type=int, default=10)
    p.add_argument("--local-epochs", type=int, default=2)
    p.add_argument("--bits", type=int, default=8)
    p.add_argument("--batch", type=int, default=4)  # é»˜è®¤è°ƒå°
    p.add_argument("--imgsz", type=int, default=640)
    p.add_argument("--device", type=str, default="cuda:0")
    p.add_argument("--workers", type=int, default=0)
    p.add_argument("--out-dir", type=str, default="./results/runs_flq_v5")
    return p.parse_args()


def main():
    args = parse_args()
    run_federated_flq(
        [Path(p) for p in args.clients], Path(args.val_data), Path(args.model),
        args.rounds, args.local_epochs, args.bits, args.batch, args.imgsz,
        args.device, args.workers, Path(args.out_dir)
    )


if __name__ == "__main__":
    main()
